{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
        "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
      },
      "cell_type": "markdown",
      "source": "### Previous days\n\n* [Day 1: Handling missing values](https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values)\n* [Day 2: Scaling and normalization](https://www.kaggle.com/rtatman/data-cleaning-challenge-scale-and-normalize-data)\n* [Day 3: Parsing dates](https://www.kaggle.com/rtatman/data-cleaning-challenge-parsing-dates/)\n* [Day 4: Character encodings](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/)\n___\n\nWelcome to day 5 of the 5-Day Data Challenge! (Can you believe it's already been five days??) Today, we're going to learn how to clean up inconsistent text entries. To get started, click the blue \"Fork Notebook\" button in the upper, right hand corner. This will create a private copy of this notebook that you can edit and play with. Once you're finished with the exercises, you can choose to make your notebook public to share with others. :)\n\n> **Your turn!** As we work through this notebook, you'll see some notebook cells (a block of either code or text) that has \"Your Turn!\" written in it. These are exercises for you to do to help cement your understanding of the concepts we're talking about. Once you've written the code to answer a specific question, you can run the code by clicking inside the cell (box with code in it) with the code you want to run and then hit CTRL + ENTER (CMD + ENTER on a Mac). You can also click in a cell and then click on the right \"play\" arrow to the left of the code. If you want to run all the code in your notebook, you can use the double, \"fast forward\" arrows at the bottom of the notebook editor.\n\nHere's what we're going to do today:\n\n* [Get our environment set up](#Get-our-environment-set-up)\n* [Do some preliminary text pre-processing](#Do-some-preliminary-text-pre-processing)\n* [Use fuzzy matching to correct inconsistent data entry](#Use-fuzzy-matching-to-correct-inconsistent-data-entry)\n\n\nLet's get started!"
    },
    {
      "metadata": {
        "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
        "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
      },
      "cell_type": "markdown",
      "source": "# Get our environment set up\n________\n\nThe first thing we'll need to do is load in the libraries we'll be using. Not our datasets, though: we'll get to those later!\n\n> **Important!** Make sure you run this cell yourself or the rest of your code won't work!"
    },
    {
      "metadata": {
        "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
        "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# helpful modules\nimport fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\n# set seed for reproducibility\nnp.random.seed(0)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5169ae8c-6210-400a-ace2-e5fbe00378fc",
        "_uuid": "ed09d242e94e22f1bac2dc446d7545b1d1f5d5c5"
      },
      "cell_type": "markdown",
      "source": "When I tried to read in the `PakistanSuicideAttacks Ver 11 (30-November-2017).csv`file the first time, I got a character encoding error, so I'm going to quickly check out what the encoding should be..."
    },
    {
      "metadata": {
        "_cell_guid": "ee54b6ee-0869-438a-9b6f-57c6d67f923f",
        "_uuid": "d2578d4d4bc7e42f5ab6157d9c3eb40e68d42e9b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# look at the first ten thousand bytes to guess the character encoding\nwith open(\"../input/PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", 'rb') as rawdata:\n    result = chardet.detect(rawdata.read(100000))\n\n# check what the character encoding might be\nprint(result)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "6a60be35-cd57-4dcc-9b98-c365de041332",
        "_uuid": "71d00770de8e42e926d8dc5a3a8b48b2c368ea43"
      },
      "cell_type": "markdown",
      "source": "![](http://)![](http://)<font color = 'red'>And then read it in with the correct encoding<font color = 'black'>. (If this look unfamiliar to you, check out [yesterday's challenge](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/).) "
    },
    {
      "metadata": {
        "_cell_guid": "0f40ed87-fc61-4a61-b230-6af1f4618114",
        "_uuid": "c82584427932f3f0ccd21c7d1eca92f62476ed0a",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# read in our dat\nsuicide_attacks = pd.read_csv(\"../input/PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", \n                              encoding='Windows-1252')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "83630dd4-6775-4ba5-a290-077c6f503f64",
        "_uuid": "a3f42cea88795426f036e35d30d5c079f3c6152c"
      },
      "cell_type": "markdown",
      "source": "Now we're ready to get started! You can, as always, take a moment here to look at the data and get familiar with it. :)\n\n\n# Do some preliminary text pre-processing\n___\n\nFor this exercise, I'm interested in cleaning up the \"City\" column to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this though!"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfd07b88278b74a7ffdcba0611ecd533d9f041fa"
      },
      "cell_type": "code",
      "source": "suicide_attacks.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   S#                     Date                   Islamic Date Blast Day Type  \\\n0   1  Sunday-November 19-1995  25 Jumaada al-THaany 1416 A.H        Holiday   \n1   2   Monday-November 6-2000           10 SHa`baan 1421 A.H    Working Day   \n2   3     Wednesday-May 8-2002              25 safar 1423 A.H    Working Day   \n3   4      Friday-June 14-2002     3 Raby` al-THaany 1423 A.H    Working Day   \n4   5       Friday-July 4-2003     4 Jumaada al-awal 1424 A.H    Working Day   \n\n  Holiday Type         Time       City  Latitude Longitude     Province  \\\n0      Weekend          NaN  Islamabad   33.7180   73.0718      Capital   \n1          NaN          NaN    Karachi   24.9918   66.9911        Sindh   \n2          NaN      7:45 AM   Karachi    24.9918   66.9911        Sindh   \n3          NaN  11:10:00 AM    Karachi   24.9918   66.9911        Sindh   \n4          NaN          NaN     Quetta   30.2095   67.0182  Baluchistan   \n\n        ...       Targeted Sect if any Killed Min Killed Max Injured Min  \\\n0       ...                       None       14.0       15.0         NaN   \n1       ...                       None        NaN        3.0         NaN   \n2       ...                  Christian       13.0       15.0        20.0   \n3       ...                  Christian        NaN       12.0         NaN   \n4       ...                     Shiite       44.0       47.0         NaN   \n\n  Injured Max No. of Suicide Blasts Explosive Weight (max)  \\\n0          60                   2.0                    NaN   \n1           3                   1.0                    NaN   \n2          40                   1.0                 2.5 Kg   \n3          51                   1.0                    NaN   \n4          65                   1.0                    NaN   \n\n                                      Hospital Names  Temperature(C)  \\\n0                                                NaN          15.835   \n1                                                NaN          23.770   \n2  1.Jinnah Postgraduate Medical Center 2. Civil ...          31.460   \n3                                                NaN          31.430   \n4  1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...          33.120   \n\n   Temperature(F)  \n0          60.503  \n1          74.786  \n2          88.628  \n3          88.574  \n4          91.616  \n\n[5 rows x 26 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S#</th>\n      <th>Date</th>\n      <th>Islamic Date</th>\n      <th>Blast Day Type</th>\n      <th>Holiday Type</th>\n      <th>Time</th>\n      <th>City</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Province</th>\n      <th>...</th>\n      <th>Targeted Sect if any</th>\n      <th>Killed Min</th>\n      <th>Killed Max</th>\n      <th>Injured Min</th>\n      <th>Injured Max</th>\n      <th>No. of Suicide Blasts</th>\n      <th>Explosive Weight (max)</th>\n      <th>Hospital Names</th>\n      <th>Temperature(C)</th>\n      <th>Temperature(F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Sunday-November 19-1995</td>\n      <td>25 Jumaada al-THaany 1416 A.H</td>\n      <td>Holiday</td>\n      <td>Weekend</td>\n      <td>NaN</td>\n      <td>Islamabad</td>\n      <td>33.7180</td>\n      <td>73.0718</td>\n      <td>Capital</td>\n      <td>...</td>\n      <td>None</td>\n      <td>14.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.835</td>\n      <td>60.503</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Monday-November 6-2000</td>\n      <td>10 SHa`baan 1421 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.770</td>\n      <td>74.786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Wednesday-May 8-2002</td>\n      <td>25 safar 1423 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>7:45 AM</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>Christian</td>\n      <td>13.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>40</td>\n      <td>1.0</td>\n      <td>2.5 Kg</td>\n      <td>1.Jinnah Postgraduate Medical Center 2. Civil ...</td>\n      <td>31.460</td>\n      <td>88.628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Friday-June 14-2002</td>\n      <td>3 Raby` al-THaany 1423 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>11:10:00 AM</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>Christian</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>51</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31.430</td>\n      <td>88.574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Friday-July 4-2003</td>\n      <td>4 Jumaada al-awal 1424 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Quetta</td>\n      <td>30.2095</td>\n      <td>67.0182</td>\n      <td>Baluchistan</td>\n      <td>...</td>\n      <td>Shiite</td>\n      <td>44.0</td>\n      <td>47.0</td>\n      <td>NaN</td>\n      <td>65</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...</td>\n      <td>33.120</td>\n      <td>91.616</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b3d4b17e-77c4-46d8-9681-a94801969b49",
        "_uuid": "4bced8b6f6a985ded2c991f46ed0145ac1d8b722",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get all the unique values in the 'City' column\ncities = suicide_attacks['City'].unique()\n\n# sort them alphabetically and then take a closer look\ncities.sort()  # sorting cities name by alphabetical order\ncities",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "array(['ATTOCK', 'Attock ', 'Bajaur Agency', 'Bannu', 'Bhakkar ', 'Buner',\n       'Chakwal ', 'Chaman', 'Charsadda', 'Charsadda ', 'D. I Khan',\n       'D.G Khan', 'D.G Khan ', 'D.I Khan', 'D.I Khan ', 'Dara Adam Khel',\n       'Dara Adam khel', 'Fateh Jang', 'Ghallanai, Mohmand Agency ',\n       'Gujrat', 'Hangu', 'Haripur', 'Hayatabad', 'Islamabad',\n       'Islamabad ', 'Jacobabad', 'KURRAM AGENCY', 'Karachi', 'Karachi ',\n       'Karak', 'Khanewal', 'Khuzdar', 'Khyber Agency', 'Khyber Agency ',\n       'Kohat', 'Kohat ', 'Kuram Agency ', 'Lahore', 'Lahore ',\n       'Lakki Marwat', 'Lakki marwat', 'Lasbela', 'Lower Dir', 'MULTAN',\n       'Malakand ', 'Mansehra', 'Mardan', 'Mohmand Agency',\n       'Mohmand Agency ', 'Mohmand agency', 'Mosal Kor, Mohmand Agency',\n       'Multan', 'Muzaffarabad', 'North Waziristan', 'North waziristan',\n       'Nowshehra', 'Orakzai Agency', 'Peshawar', 'Peshawar ', 'Pishin',\n       'Poonch', 'Quetta', 'Quetta ', 'Rawalpindi', 'Sargodha',\n       'Sehwan town', 'Shabqadar-Charsadda', 'Shangla ', 'Shikarpur',\n       'Sialkot', 'South Waziristan', 'South waziristan', 'Sudhanoti',\n       'Sukkur', 'Swabi ', 'Swat', 'Swat ', 'Taftan',\n       'Tangi, Charsadda District', 'Tank', 'Tank ', 'Taunsa',\n       'Tirah Valley', 'Totalai', 'Upper Dir', 'Wagah', 'Zhob', 'bannu',\n       'karachi', 'karachi ', 'lakki marwat', 'peshawar', 'swat'],\n      dtype=object)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c11d7808-e677-4ec3-a357-0a3e9bed4cf5",
        "_uuid": "8785e8cc59b40e6ac7a824184132460e22a99f87"
      },
      "cell_type": "markdown",
      "source": "Just looking at this, <font color = 'red'>I can see some problems due to inconsistent data entry<font color = 'black'>: 'Lahore' and 'Lahore ' , for example, or 'Lakki Marwat' and 'Lakki marwat'.\n\n<font color = 'red'>The first thing I'm going to do is make everything lower case<font color = 'black'> (I can change it back at the end if I like) and remove any white spaces at the beginning and end of cells.<font color = 'red'> Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
    },
    {
      "metadata": {
        "_cell_guid": "61651d57-f28c-4b81-bd05-b82720a8ed18",
        "_uuid": "2b604c74492419f89a43262d1f811e272646f9a6",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# convert to lower case\nsuicide_attacks['City'] = suicide_attacks['City'].str.lower()\n# remove trailing white spaces\nsuicide_attacks['City'] = suicide_attacks['City'].str.strip()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "be205adc4a01d6aa1dbeb5c1874e74f49eecea5d"
      },
      "cell_type": "code",
      "source": "suicide_attacks.City",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0                      islamabad\n1                        karachi\n2                        karachi\n3                        karachi\n4                         quetta\n5                     rawalpindi\n6                     rawalpindi\n7                        karachi\n8                        karachi\n9               north waziristan\n10                         kohat\n11                        attock\n12                       sialkot\n13                        lahore\n14                        quetta\n15                          swat\n16                     islamabad\n17                       karachi\n18                         hangu\n19                       karachi\n20                       karachi\n21                         bannu\n22              north waziristan\n23                       lasbela\n24                      malakand\n25                      peshawar\n26                         bannu\n27              north waziristan\n28                     islamabad\n29                      peshawar\n                 ...            \n466                       mardan\n467                       mardan\n468                       quetta\n469                       mardan\n470                    shikarpur\n471               mohmand agency\n472                       quetta\n473                      khuzdar\n474               mohmand agency\n475                        bannu\n476                       lahore\n477    ghallanai, mohmand agency\n478                    hayatabad\n479    mosal kor, mohmand agency\n480                  sehwan town\n481    tangi, charsadda district\n482                       lahore\n483                       quetta\n484                        kohat\n485                       quetta\n486                       chaman\n487                     peshawar\n488                     peshawar\n489                       lahore\n490                       quetta\n491                       quetta\n492                       quetta\n493                       quetta\n494                     peshawar\n495                       quetta\nName: City, Length: 496, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "4c11e916-981a-41c3-b79f-9ac60521d6a2",
        "_uuid": "29388ff41b320262a8fe17a8f2a347ae919bad7c"
      },
      "cell_type": "markdown",
      "source": "Next we're going to tackle more difficult inconsistencies."
    },
    {
      "metadata": {
        "_cell_guid": "3deb3f1b-80e0-4a94-9bf7-1c9cd4882c18",
        "_uuid": "27aeda660f0e95ccb24bf8c5c1e1d5cfb22be7a8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! Take a look at all the unique values in the \"Province\" column. \n# Then convert the column to lowercase and remove any trailing white spaces\n\nsuicide_attacks.Province.unique()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array(['Capital', 'Sindh', 'Baluchistan', 'Punjab', 'FATA', 'KPK', 'AJK',\n       'Fata', 'Balochistan'], dtype=object)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "ae67191fc452285c22a1c6e577e6b3033ab3fba8"
      },
      "cell_type": "code",
      "source": "\nsuicide_attacks.Province = suicide_attacks.Province.str.lower()\nsuicide_attacks.Province = suicide_attacks.Province.str.strip()\n\nprint(suicide_attacks.Province.unique())\n# print(suicide_attacks.Province)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['capital' 'sindh' 'baluchistan' 'punjab' 'fata' 'kpk' 'ajk' 'balochistan']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a612e0fa-1361-4e8e-a6aa-5008b631d076",
        "_uuid": "3639865348f499faa25b75a46438807ed70d4173"
      },
      "cell_type": "markdown",
      "source": "# Use fuzzy matching to correct inconsistent data entry\n___\n\nAlright, <font color = 'red'>let's take another look at the city column and see if there's any more data cleaning we need to do."
    },
    {
      "metadata": {
        "_cell_guid": "8f20fd24-33a4-472d-ba22-be0abc2a1e5b",
        "_uuid": "1408dacdd7b76f306bd1c0c534b991d76243d7cc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get all the unique values in the 'City' column\ncities = suicide_attacks['City'].unique()\n\n# sort them alphabetically and then take a closer look\ncities.sort()\ncities",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n       'mansehra', 'mardan', 'mohmand agency',\n       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "dcbefc7e-702c-4b5a-86ab-f0c2f93f3873",
        "_uuid": "b092eca650105d8fe8b15f85fbe2747003b4f170"
      },
      "cell_type": "markdown",
      "source": "It does look like there are some remaining inconsistencies: 'd. i khan' and 'd.i khan' should probably be the same. (I [looked it up](https://en.wikipedia.org/wiki/List_of_most_populous_cities_in_Pakistan) and '<font color = 'red'>d.g khan' is a seperate city, so I shouldn't combine those.<font color = 'black'>) \n\nI'm going to use the [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) package to help identify which string are closest to each other. This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea. Plus, it’s fun! :)\n\n> **Fuzzy matching:** The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n\n<font color = 'red'> Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"d.i khan\"."
    },
    {
      "metadata": {
        "_cell_guid": "4fdcd726-4a4f-4348-b745-1e42c3338100",
        "_uuid": "a53c6f011f5c9144e9a48f329d5cf15e2feddec8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get the top 10 closest matches to \"d.i khan\"\nmatches = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n# take a look at them\nmatches",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "[('d. i khan', 100),\n ('d.i khan', 100),\n ('d.g khan', 88),\n ('khanewal', 50),\n ('sudhanoti', 47),\n ('hangu', 46),\n ('kohat', 46),\n ('dara adam khel', 45),\n ('chaman', 43),\n ('mardan', 43)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "4c565201-9ccf-4138-81ce-84379a578a23",
        "_uuid": "e31474068514e35c65bb9d16d58bbb7e5f1226ce"
      },
      "cell_type": "markdown",
      "source": "We can see that two of the items in the cities are very close to \"d.i khan\": \"d. i khan\" and \"d.i khan\". We can also see the \"d.g khan\", which is a seperate city, has a ratio of 88.<font color = 'red'> Since we don't want to replace \"d.g khan\" with \"d.i khan\", let's replace all rows in our City column that have a ratio of > 90 with \"d. i khan\". <font color = 'black'>\n\nTo do this, I'm going to write a function. ( <font color = 'red'>It's a good idea to write a general purpose function you can reuse if you think you might have to do a specific task more than once or twice<font color = 'black'>. This keeps you from having to copy and paste code too often, which saves time and can help prevent mistakes.)"
    },
    {
      "metadata": {
        "_cell_guid": "57f719c6-1261-46da-93ac-b2742108bdc1",
        "_uuid": "e518a51a3969956e8259e323bd03c62fc99a830c",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function to replace rows in the provided column of the provided dataframe\n# that match the provided string above the provided ratio with the provided string\ndef replace_matches_in_column(df, column, string_to_match, min_ratio = 90): ### we're writing a general function here so that we can pass another string in future\n    # get a list of unique strings\n    strings = df[column].unique()\n    \n    # get the top 10 closest matches to our input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n\n    # only get matches with a ratio > 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n\n    # get the rows of all the close matches in our dataframe\n    rows_with_matches = df[column].isin(close_matches)\n\n    # replace all rows with close matches with the input matches \n    df.loc[rows_with_matches, column] = string_to_match\n    \n    # let us know the function's done\n    print(\"All done!\")",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ff22a98d-2919-436f-b921-151364f97fc9",
        "_uuid": "555c4f9d53db48869becbf5efd054e6e73570990"
      },
      "cell_type": "markdown",
      "source": "Now that we have a function, we can put it to the test!"
    },
    {
      "metadata": {
        "_cell_guid": "dcc0e515-c207-48cd-906e-4f8aae597f18",
        "_uuid": "846464842c3537f6bf41eb1db6d09c11fedc1f99",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# use the function we just wrote to replace close matches to \"d.i khan\" with \"d.i khan\"\nreplace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "All done!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "dd1868c5-329f-4db6-b5ce-cfa940daf084",
        "_uuid": "2c284b82c0d22189e998a034807f98e9a01fe228"
      },
      "cell_type": "markdown",
      "source": "And now let's can check the unique values in our City column again and make sure we've tidied up d.i khan correctly."
    },
    {
      "metadata": {
        "_cell_guid": "b695e089-86b4-415a-9c99-d42ff9d7e4ee",
        "_uuid": "ef869fbc043758259d6eafe599532468692eb15c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get all the unique values in the 'City' column\ncities = suicide_attacks['City'].unique()\n\n# sort them alphabetically and then take a closer look\ncities.sort()\ncities",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd.g khan', 'd.i khan', 'dara adam khel',\n       'fateh jang', 'ghallanai, mohmand agency', 'gujrat', 'hangu',\n       'haripur', 'hayatabad', 'islamabad', 'jacobabad', 'karachi',\n       'karak', 'khanewal', 'khuzdar', 'khyber agency', 'kohat',\n       'kuram agency', 'kurram agency', 'lahore', 'lakki marwat',\n       'lasbela', 'lower dir', 'malakand', 'mansehra', 'mardan',\n       'mohmand agency', 'mosal kor, mohmand agency', 'multan',\n       'muzaffarabad', 'north waziristan', 'nowshehra', 'orakzai agency',\n       'peshawar', 'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c46d9305-0786-47f7-b8d3-56accaa4a633",
        "_uuid": "4d43bc9b0bc6997a6c6454ff2a21aa0a296a8571"
      },
      "cell_type": "markdown",
      "source": "Excellent! Now we only have \"d.i khan\" in our dataframe and we didn't have to change anything by hand. "
    },
    {
      "metadata": {
        "_cell_guid": "0922e215-9abb-4b44-9060-7b52080fae90",
        "_uuid": "bfb366a27a3995fe253a662dd09f453afba117f6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Your turn! It looks like 'kuram agency' and 'kurram agency' should\n# be the same city. Correct the dataframe so that they are.\nreplace_matches_in_column(suicide_attacks, 'City', 'kuram agency')  # we have passed df , so that the func is more generalized instead of  passing  the \n# column 'City' of the df, i.e ( suicide_attacks.City), so that we can use the same function for Province as well. ",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "All done!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
        "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
      },
      "cell_type": "markdown",
      "source": "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n\nRemember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also lets you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n\n# More practice!\n___\n\nDo any other columns in this dataframe have inconsistent data entry? If you can find any, try to tidy them up.\n\nYou can also try reading in the `PakistanSuicideAttacks Ver 6 (10-October-2017).csv` file from this dataset and tidying up any inconsistent columns in that data file."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "190247fabb49b5bbaa93efc45cb307ea07f3ce8c"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}